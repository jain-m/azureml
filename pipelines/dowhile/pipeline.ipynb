{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build ML Pipeline with do-while node\n",
    "\n",
    "In the [get started](../../../samples/basics//get-started.ipynb) tutorial we have introduced how to build an ML pipeline by using Azure Machine Learning components. In this tutorial, you will learn how to build pipeline with do-while node.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "* Install azure cli with azure-cli-ml extension following the [instructions here](setup-environment.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1 Enable private features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "\n",
    "\n",
    "# enable private features\n",
    "os.environ[\"AZURE_ML_CLI_PRIVATE_FEATURES_ENABLED\"] = \"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Get a handle to the workspace\n",
    "\n",
    "We use config file to connect to a workspace. The Azure ML workspace should be configured with computer cluster. [Check this notebook for configure a workspace](../../configuration.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "# Get a handle to workspace\n",
    "ml_client = MLClient.from_config(credential=credential)\n",
    "\n",
    "# Retrieve an already attached Azure Machine Learning Compute.\n",
    "cluster_name = \"cpu-cluster\"\n",
    "print(ml_client.compute.get(cluster_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build pipeline with do-while node\n",
    "### 2.1 Build sub pipeline as the body of do-while node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from components.aggregate_train.aggregate_train_model import (\n",
    "    aggregated_train as aggregate_train_model_func,\n",
    ")\n",
    "from components.process_data.process_data import process_data as process_data_func\n",
    "from components.train_model.train_model import train_model as train_model_func\n",
    "\n",
    "\n",
    "@pipeline()\n",
    "def silo_pipeline(input_model: Input):\n",
    "    \"\"\"Silo for each iteration in federated learning, contains pre_process, training and post_process.\"\"\"\n",
    "    pre_data_process = process_data_func(input_data=input_model)\n",
    "    training_node = train_model_func(input_model=pre_data_process.outputs.output_data)\n",
    "    post_data_process = process_data_func(input_data=training_node.outputs.output_model)\n",
    "    return post_data_process.outputs\n",
    "\n",
    "\n",
    "@pipeline()\n",
    "def federated_learning_body(input_model: Input):\n",
    "    \"\"\"Body of each iteration of federated learning, include multi silos and aggregate node.\"\"\"\n",
    "    silo_1 = silo_pipeline(input_model=input_model)\n",
    "    silo_2 = silo_pipeline(input_model=input_model)\n",
    "    aggregate_node = aggregate_train_model_func(\n",
    "        model_1=silo_1.outputs.output_data,\n",
    "        model_2=silo_2.outputs.output_data,\n",
    "    )\n",
    "    return aggregate_node.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Build parent pipeline with do-while node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mldesigner import dsl\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "\n",
    "# define pipeline with do_while node\n",
    "@pipeline()\n",
    "def federated_learning_pipeline(train_model: Input):\n",
    "    # federated_learning iteration body\n",
    "    loop_body = federated_learning_body(input_model=train_model)\n",
    "    federated_learning_dowhile_node = dsl.do_while(  # noqa: F841\n",
    "        body=loop_body,\n",
    "        condition=loop_body.outputs.output,\n",
    "        mapping={\n",
    "            \"agg_output\": loop_body.inputs.input_model,\n",
    "        },\n",
    "        max_iteration_count=5,\n",
    "    )\n",
    "    aggregate_node = aggregate_train_model_func(\n",
    "        model_1=loop_body.outputs.agg_output,\n",
    "        model_2=loop_body.outputs.agg_output,\n",
    "    )\n",
    "\n",
    "\n",
    "pipeline_job = federated_learning_pipeline(\n",
    "    train_model=Input(path=\"./dummy_model\", type=\"custom_model\")\n",
    ")\n",
    "\n",
    "# set pipeline level compute\n",
    "pipeline_job.settings.default_compute = cluster_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# validate pipeline\n",
    "ml_client.jobs.validate(pipeline_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Run pipeline job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pipeline parameter can be overridden when submit pipeline\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_job, experiment_name=\"pipeline_samples\"\n",
    ")\n",
    "\n",
    "# show detail information of job\n",
    "pipeline_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Wait until the job completes\n",
    "ml_client.jobs.stream(pipeline_job.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 ('aml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "3551cdbf41dd308c83ee4db1fe46d8eb1c4a6543e1a665da9bfd038c22734cff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
